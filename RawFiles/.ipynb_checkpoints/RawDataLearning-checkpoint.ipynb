{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get imports # import files\n",
    "from threading import Thread\n",
    "import queue as que\n",
    "import pandas as pd\n",
    "import os, pickle\n",
    "import nltk\n",
    "import math\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import nltk\n",
    "from collections import Counter \n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "cachedStopWords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#methods\n",
    "def save_it_all(obj, filename):\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "def load_objects(file):\n",
    "    with open(file, 'rb') as input:\n",
    "        return pickle.load(input)\n",
    "    \n",
    "def merge_two_dicts(x, y):\n",
    "    z = x.copy()   # start with x's keys and values\n",
    "    z.update(y)    # modifies z with y's keys and values & returns None\n",
    "    return z\n",
    "\n",
    "def seperator(docs):\n",
    "    print(len(docs))\n",
    "    txt = []\n",
    "    typesInfo = []\n",
    "    docsInfo = []\n",
    "    for line in docs:\n",
    "        words = line.split()\n",
    "        content = (\" \").join(words[1:])\n",
    "        item = (\", \").join([words[0], content])\n",
    "        txt.append(item)\n",
    "        typesInfo.append(words[0])\n",
    "        docsInfo.append(content)\n",
    "    return txt, typesInfo, docsInfo\n",
    "\n",
    "def write(data):\n",
    "    print(type(data))\n",
    "    with open('./training_data.csv', 'w') as f:\n",
    "        for item in data:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "            \n",
    "# methods\n",
    "def read(fileName):\n",
    "    with open(fileName) as f:\n",
    "        content = f.readlines()\n",
    "    # you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "    content = [x.strip() for x in content]\n",
    "    return content\n",
    "\n",
    "def save_it_all(obj, filename):\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "def load_objects(file):\n",
    "    with open(file, 'rb') as input:\n",
    "        return pickle.load(input)\n",
    "    \n",
    "def vocabDict(vocab, doc, n): # handles empty word sets\n",
    "    nk = 0\n",
    "    # n = the number of word postions for this document type\n",
    "    probability = math.log(nk + 1) - math.log(n + len(vocab))\n",
    "\n",
    "    newDict = {\"count\": 0, \"probability\":probability}\n",
    "    vdict = dict((el,newDict) for el in vocab)\n",
    "    return vdict\n",
    "\n",
    "def wordCount(doc, vocab, n): # get actual word count for each word and create dict frame to track the info\n",
    "    counts = dict(Counter(doc.tolist()[0].split()))\n",
    "    for key, value in counts.items():\n",
    "        nk = value\n",
    "        probability = math.log(nk + 1) - math.log(n + len(vocab))\n",
    "        newDict = {\"count\": nk, \"probability\": probability}\n",
    "        counts[key] = newDict\n",
    "    emptyVocab = vocabDict(vocab, doc, n)\n",
    "    dicts = [merge_two_dicts(emptyVocab, counts)]\n",
    "    return dicts\n",
    "        \n",
    "def wordProbs(dataFrame):\n",
    "    for docType in dataFrame[\"Type\"]:\n",
    "        wordCountDict = dataFrame[\"WordCount\"][dataFrame[\"Type\"]==docType].tolist()[0]\n",
    "        \n",
    "        for key in wordCountDict:\n",
    "            if dataFrame[\"WordCount\"][dataFrame[\"Type\"]==docType].tolist()[0][key] is int:\n",
    "                nk = dataFrame[\"WordCount\"][dataFrame[\"Type\"]==docType].tolist()[0][key]\n",
    "                n = dataFrame[\"WordPositions\"][dataFrame[\"Type\"]==docType].tolist()[0]\n",
    "                probability = math.log(nk + 1) - math.log(n + len(vocabStopStemmingEdit))\n",
    "                newDict = {\"count\": nk, \"probability\":probability}\n",
    "                dataFrame[\"WordCount\"][dataFrame[\"Type\"]==docType].tolist()[0][key] = newDict\n",
    "    return dataFrame\n",
    "\n",
    "def saveFrame(df, name):\n",
    "    df.to_csv(name+\".csv\", index=False, sep=\",\", header=True)\n",
    "    save_it_all(df, name+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load in files \n",
    "# # read file line by line \n",
    "# fileName = \"../forumTraining.data\"\n",
    "# data = read(fileName)\n",
    "# len(data)\n",
    "# sep_data, typesInfo, docsInfo = seperator(data)\n",
    "# # write(sep_data) not needed the raw csv it makes IS BROKEN\n",
    "# # print(len(list(set(typesInfo))))\n",
    "# # print(list(set(typesInfo)))\n",
    "# dataFrameRaw = pd.DataFrame({\"Type\": typesInfo, \"Document\": docsInfo})\n",
    "# saveFrame(dataFrameRaw, \"raw_training_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>atheism</td>\n",
       "      <td>alt atheism faq atheist resources archive name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atheism</td>\n",
       "      <td>alt atheism faq introduction to atheism archiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>atheism</td>\n",
       "      <td>re gospel dating in article mimsy umd edu mang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>atheism</td>\n",
       "      <td>re university violating separation of church s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>atheism</td>\n",
       "      <td>re soc motss et al princeton axes matching fun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Type                                           Document\n",
       "0  atheism  alt atheism faq atheist resources archive name...\n",
       "1  atheism  alt atheism faq introduction to atheism archiv...\n",
       "2  atheism  re gospel dating in article mimsy umd edu mang...\n",
       "3  atheism  re university violating separation of church s...\n",
       "4  atheism  re soc motss et al princeton axes matching fun..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_training_data = pd.read_csv(\"./raw_training_data.csv\", sep=\",\")\n",
    "raw_training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trianing data raw is held in the dataframe \"raw_training_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73712\n"
     ]
    }
   ],
   "source": [
    "# create the raw vocabulary set:\n",
    "raw_vocabulary = \" \".join(raw_training_data[\"Document\"].tolist()) # concatinates all documents in the data frame\n",
    "raw_vocabulary = list(set(raw_vocabulary.split()))\n",
    "print(len(raw_vocabulary))\n",
    "save_it_all(raw_vocabulary, \"./raw_vocabulary.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The raw vocabulary is saved in the above cell and refrenced as \"raw_vocabulary\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the learning step: make it dynamic!\n",
    "For each class cj (document type) in C\n",
    "    \n",
    "    1. Docsj ← training documents for which the classification is cj\n",
    "    \n",
    "    2. Probability estimate of a particular class: P(cj) = |Docsj| / |training documents|\n",
    "    \n",
    "    3. Textj ← create a single document per class (concatenate all Docsj)\n",
    "    \n",
    "    4. n = total number of word positions in Textj\n",
    "    \n",
    "    5. For each word wk in Vocabulary nk = number of times wk occurs in Textj\n",
    "    \n",
    "    6. Estimate of word occurrence for particular document type: P(wk | cj) = (nk + 1) / (n + |Vocabulary|)\n",
    "    \n",
    "Probability of kth word in vocabulary, given a document of type j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>atheism</td>\n",
       "      <td>alt atheism faq atheist resources archive name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atheism</td>\n",
       "      <td>alt atheism faq introduction to atheism archiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>atheism</td>\n",
       "      <td>re gospel dating in article mimsy umd edu mang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>atheism</td>\n",
       "      <td>re university violating separation of church s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>atheism</td>\n",
       "      <td>re soc motss et al princeton axes matching fun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Type                                           Document\n",
       "0  atheism  alt atheism faq atheist resources archive name...\n",
       "1  atheism  alt atheism faq introduction to atheism archiv...\n",
       "2  atheism  re gospel dating in article mimsy umd edu mang...\n",
       "3  atheism  re university violating separation of church s...\n",
       "4  atheism  re soc motss et al princeton axes matching fun..."
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in docs you want to use:\n",
    "## trainign data set for use:\n",
    "trainFrame = pd.read_csv(\"./raw_training_data.csv\", sep=\",\")\n",
    "\n",
    "## vocabulary training set for use:\n",
    "vocabulary = load_objects(\"./raw_vocabulary.pkl\")\n",
    "\n",
    "# validate:\n",
    "print(type(vocabulary))\n",
    "trainFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>autos</td>\n",
       "      <td>re saturn s pricing policy in article c vir l ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pc</td>\n",
       "      <td>wanted bus card for logitech mouse i ve acquir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mac</td>\n",
       "      <td>re nutek faces apple s wrath article read in a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>forsale</td>\n",
       "      <td>motorcycle wanted followup to kedz wpi wpi edu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baseball</td>\n",
       "      <td>spring records the orioles pitching staff agai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cryptology</td>\n",
       "      <td>ripem frequently asked questions archive name ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>medicine</td>\n",
       "      <td>info needed gaucher s disease i have a yr old ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mswindows</td>\n",
       "      <td>re is kermit available for windows from articl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>graphics</td>\n",
       "      <td>call for presentations navy sciviz vr seminar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>politics</td>\n",
       "      <td>re media horrified at perot investigating bush...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>religion</td>\n",
       "      <td>re religion and homosexuality magarret magnus ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>xwindows</td>\n",
       "      <td>th international obfuscated c code contest ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>electronics</td>\n",
       "      <td>re help with tracking device in article fba e ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>christianity</td>\n",
       "      <td>re sex education in article mar athos rutgers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>motorcycles</td>\n",
       "      <td>re lexan polish in article c soe m ns nodak ed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>space</td>\n",
       "      <td>re gravity waves was predicting gravity wave q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>guns</td>\n",
       "      <td>re gun control was re we re mad as hell at the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mideastpolitics</td>\n",
       "      <td>re islam borders was israel misisipi to ganges...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>atheism</td>\n",
       "      <td>alt atheism faq atheist resources archive name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>hockey</td>\n",
       "      <td>superstars and attendance was teemu selanne wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Type                                           Document\n",
       "0             autos  re saturn s pricing policy in article c vir l ...\n",
       "1                pc  wanted bus card for logitech mouse i ve acquir...\n",
       "2               mac  re nutek faces apple s wrath article read in a...\n",
       "3           forsale  motorcycle wanted followup to kedz wpi wpi edu...\n",
       "4          baseball  spring records the orioles pitching staff agai...\n",
       "5        cryptology  ripem frequently asked questions archive name ...\n",
       "6          medicine  info needed gaucher s disease i have a yr old ...\n",
       "7         mswindows  re is kermit available for windows from articl...\n",
       "8          graphics  call for presentations navy sciviz vr seminar ...\n",
       "9          politics  re media horrified at perot investigating bush...\n",
       "10         religion  re religion and homosexuality magarret magnus ...\n",
       "11         xwindows  th international obfuscated c code contest ope...\n",
       "12      electronics  re help with tracking device in article fba e ...\n",
       "13     christianity  re sex education in article mar athos rutgers ...\n",
       "14      motorcycles  re lexan polish in article c soe m ns nodak ed...\n",
       "15            space  re gravity waves was predicting gravity wave q...\n",
       "16             guns  re gun control was re we re mad as hell at the...\n",
       "17  mideastpolitics  re islam borders was israel misisipi to ganges...\n",
       "18          atheism  alt atheism faq atheist resources archive name...\n",
       "19           hockey  superstars and attendance was teemu selanne wa..."
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# single docs per class\n",
    "types = list(set(trainFrame[\"Type\"]))\n",
    "singleFrame = pd.DataFrame({\"Type\":types , \"Document\": None})\n",
    "# singleFrame.head(20)\n",
    "for docType in singleFrame[\"Type\"]:\n",
    "    #print(trainFrame[\"Document\"][trainFrame[\"Type\"]==docType])\n",
    "    singleFrame[\"Document\"][singleFrame[\"Type\"]== docType] = \" \".join(trainFrame[\"Document\"][trainFrame[\"Type\"]==docType].tolist())\n",
    "singleFrame.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of the single frame \n",
    "rawDataInfoFrame = singleFrame.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability estimate of the class\n",
    "rawDataInfoFrame[\"ClassProbability\"] = None\n",
    "for docType in rawDataInfoFrame[\"Type\"]:\n",
    "    rawDataInfoFrame[\"ClassProbability\"][rawDataInfoFrame[\"Type\"]== docType] = len(trainFrame[\"Document\"][trainFrame[\"Type\"]== docType].tolist())/trainFrame[\"Type\"].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Document</th>\n",
       "      <th>ClassProbability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>autos</td>\n",
       "      <td>re saturn s pricing policy in article c vir l ...</td>\n",
       "      <td>0.052599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pc</td>\n",
       "      <td>wanted bus card for logitech mouse i ve acquir...</td>\n",
       "      <td>0.0522448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mac</td>\n",
       "      <td>re nutek faces apple s wrath article read in a...</td>\n",
       "      <td>0.0511821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>forsale</td>\n",
       "      <td>motorcycle wanted followup to kedz wpi wpi edu...</td>\n",
       "      <td>0.051802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baseball</td>\n",
       "      <td>spring records the orioles pitching staff agai...</td>\n",
       "      <td>0.0528646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Type                                           Document  \\\n",
       "0     autos  re saturn s pricing policy in article c vir l ...   \n",
       "1        pc  wanted bus card for logitech mouse i ve acquir...   \n",
       "2       mac  re nutek faces apple s wrath article read in a...   \n",
       "3   forsale  motorcycle wanted followup to kedz wpi wpi edu...   \n",
       "4  baseball  spring records the orioles pitching staff agai...   \n",
       "\n",
       "  ClassProbability  \n",
       "0         0.052599  \n",
       "1        0.0522448  \n",
       "2        0.0511821  \n",
       "3         0.051802  \n",
       "4        0.0528646  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawDataInfoFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the word postions:\n",
    "rawDataInfoFrame[\"WordPositions\"] = None\n",
    "for docType in rawDataInfoFrame[\"Type\"]:\n",
    "    rawDataInfoFrame[\"WordPositions\"][rawDataInfoFrame[\"Type\"]== docType] = len(rawDataInfoFrame[\"Document\"][rawDataInfoFrame[\"Type\"]== docType].tolist()[0].split())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Document</th>\n",
       "      <th>ClassProbability</th>\n",
       "      <th>WordPositions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>autos</td>\n",
       "      <td>re saturn s pricing policy in article c vir l ...</td>\n",
       "      <td>0.052599</td>\n",
       "      <td>127696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pc</td>\n",
       "      <td>wanted bus card for logitech mouse i ve acquir...</td>\n",
       "      <td>0.0522448</td>\n",
       "      <td>112583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mac</td>\n",
       "      <td>re nutek faces apple s wrath article read in a...</td>\n",
       "      <td>0.0511821</td>\n",
       "      <td>97182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>forsale</td>\n",
       "      <td>motorcycle wanted followup to kedz wpi wpi edu...</td>\n",
       "      <td>0.051802</td>\n",
       "      <td>69761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baseball</td>\n",
       "      <td>spring records the orioles pitching staff agai...</td>\n",
       "      <td>0.0528646</td>\n",
       "      <td>119407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Type                                           Document  \\\n",
       "0     autos  re saturn s pricing policy in article c vir l ...   \n",
       "1        pc  wanted bus card for logitech mouse i ve acquir...   \n",
       "2       mac  re nutek faces apple s wrath article read in a...   \n",
       "3   forsale  motorcycle wanted followup to kedz wpi wpi edu...   \n",
       "4  baseball  spring records the orioles pitching staff agai...   \n",
       "\n",
       "  ClassProbability WordPositions  \n",
       "0         0.052599        127696  \n",
       "1        0.0522448        112583  \n",
       "2        0.0511821         97182  \n",
       "3         0.051802         69761  \n",
       "4        0.0528646        119407  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawDataInfoFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word count \n",
    "rawDataInfoFrame[\"WordCount\"] = None\n",
    "for docType in rawDataInfoFrame[\"Type\"]:\n",
    "    n = rawDataInfoFrame[\"WordPositions\"][rawDataInfoFrame[\"Type\"] == docType]\n",
    "    rawDataInfoFrame[\"WordCount\"][rawDataInfoFrame[\"Type\"] == docType] = wordCount(rawDataInfoFrame[\"Document\"][rawDataInfoFrame[\"Type\"]==docType], vocabulary, n)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Document</th>\n",
       "      <th>ClassProbability</th>\n",
       "      <th>WordPositions</th>\n",
       "      <th>WordCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>autos</td>\n",
       "      <td>re saturn s pricing policy in article c vir l ...</td>\n",
       "      <td>0.052599</td>\n",
       "      <td>127696</td>\n",
       "      <td>{'akin': {'count': 0, 'probability': -12.21308...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pc</td>\n",
       "      <td>wanted bus card for logitech mouse i ve acquir...</td>\n",
       "      <td>0.0522448</td>\n",
       "      <td>112583</td>\n",
       "      <td>{'akin': {'count': 0, 'probability': -12.13508...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mac</td>\n",
       "      <td>re nutek faces apple s wrath article read in a...</td>\n",
       "      <td>0.0511821</td>\n",
       "      <td>97182</td>\n",
       "      <td>{'akin': {'count': 0, 'probability': -12.04879...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>forsale</td>\n",
       "      <td>motorcycle wanted followup to kedz wpi wpi edu...</td>\n",
       "      <td>0.051802</td>\n",
       "      <td>69761</td>\n",
       "      <td>{'akin': {'count': 0, 'probability': -11.87390...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baseball</td>\n",
       "      <td>spring records the orioles pitching staff agai...</td>\n",
       "      <td>0.0528646</td>\n",
       "      <td>119407</td>\n",
       "      <td>{'akin': {'count': 0, 'probability': -12.17106...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Type                                           Document  \\\n",
       "0     autos  re saturn s pricing policy in article c vir l ...   \n",
       "1        pc  wanted bus card for logitech mouse i ve acquir...   \n",
       "2       mac  re nutek faces apple s wrath article read in a...   \n",
       "3   forsale  motorcycle wanted followup to kedz wpi wpi edu...   \n",
       "4  baseball  spring records the orioles pitching staff agai...   \n",
       "\n",
       "  ClassProbability WordPositions  \\\n",
       "0         0.052599        127696   \n",
       "1        0.0522448        112583   \n",
       "2        0.0511821         97182   \n",
       "3         0.051802         69761   \n",
       "4        0.0528646        119407   \n",
       "\n",
       "                                           WordCount  \n",
       "0  {'akin': {'count': 0, 'probability': -12.21308...  \n",
       "1  {'akin': {'count': 0, 'probability': -12.13508...  \n",
       "2  {'akin': {'count': 0, 'probability': -12.04879...  \n",
       "3  {'akin': {'count': 0, 'probability': -11.87390...  \n",
       "4  {'akin': {'count': 0, 'probability': -12.17106...  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawDataInfoFrame.head()\n",
    "# rawDataInfoFrame[\"WordCount\"][rawDataInfoFrame[\"Type\"] == \"autos\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveFrame(rawDataInfoFrame, \"./raw_data_info_frame.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
