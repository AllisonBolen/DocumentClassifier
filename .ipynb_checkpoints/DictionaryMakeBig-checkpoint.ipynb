{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from threading import Thread\n",
    "import os, math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# take all the trained data frames and make them big dicts by \n",
    "\n",
    "word-class: probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_it_all(obj, filename):\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "def load_objects(file):\n",
    "    with open(file, 'rb') as input:\n",
    "        return pickle.load(input)\n",
    "\n",
    "def saveFrame(df, name):\n",
    "    df.to_csv(name+\".csv\", index=False, sep=\",\", header=True)\n",
    "    save_it_all(df, name+\".pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in raw data frame\n",
    "## trained data info data set for use:\n",
    "raw_trained_frame = load_objects(\"../RawFiles/raw_data_info_frame.pkl\")\n",
    "\n",
    "stop_trained_frame = load_objects(\"./stop_training_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Document</th>\n",
       "      <th>ClassProbability</th>\n",
       "      <th>WordPositions</th>\n",
       "      <th>WordCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mideastpolitics</td>\n",
       "      <td>re islam borders was israel misisipi to ganges...</td>\n",
       "      <td>0.0499424</td>\n",
       "      <td>272488</td>\n",
       "      <td>{'hepis': {'count': 0, 'probability': 2.888503...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politics</td>\n",
       "      <td>re media horrified at perot investigating bush...</td>\n",
       "      <td>0.0411759</td>\n",
       "      <td>202625</td>\n",
       "      <td>{'hepis': {'count': 0, 'probability': 3.618769...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>religion</td>\n",
       "      <td>re religion and homosexuality magarret magnus ...</td>\n",
       "      <td>0.0333835</td>\n",
       "      <td>129611</td>\n",
       "      <td>{'hepis': {'count': 0, 'probability': 4.918282...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mac</td>\n",
       "      <td>re nutek faces apple s wrath article read in a...</td>\n",
       "      <td>0.0511821</td>\n",
       "      <td>97182</td>\n",
       "      <td>{'hepis': {'count': 0, 'probability': 5.851580...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>forsale</td>\n",
       "      <td>motorcycle wanted followup to kedz wpi wpi edu...</td>\n",
       "      <td>0.051802</td>\n",
       "      <td>69761</td>\n",
       "      <td>{'hepis': {'count': 0, 'probability': 6.969952...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Type                                           Document  \\\n",
       "0  mideastpolitics  re islam borders was israel misisipi to ganges...   \n",
       "1         politics  re media horrified at perot investigating bush...   \n",
       "2         religion  re religion and homosexuality magarret magnus ...   \n",
       "3              mac  re nutek faces apple s wrath article read in a...   \n",
       "4          forsale  motorcycle wanted followup to kedz wpi wpi edu...   \n",
       "\n",
       "  ClassProbability WordPositions  \\\n",
       "0        0.0499424        272488   \n",
       "1        0.0411759        202625   \n",
       "2        0.0333835        129611   \n",
       "3        0.0511821         97182   \n",
       "4         0.051802         69761   \n",
       "\n",
       "                                           WordCount  \n",
       "0  {'hepis': {'count': 0, 'probability': 2.888503...  \n",
       "1  {'hepis': {'count': 0, 'probability': 3.618769...  \n",
       "2  {'hepis': {'count': 0, 'probability': 4.918282...  \n",
       "3  {'hepis': {'count': 0, 'probability': 5.851580...  \n",
       "4  {'hepis': {'count': 0, 'probability': 6.969952...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_trained_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dictionary for raw:\n",
    "rawBigDict = {}\n",
    "for docType in raw_trained_frame[\"Type\"]:\n",
    "    for key, value in raw_trained_frame[\"WordCount\"][raw_trained_frame[\"Type\"]==docType].tolist()[0].items():\n",
    "        #print(key + str(value))\n",
    "        rawBigDict[key+\"-\"+docType]=value[\"probability\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawBigDict\n",
    "save_it_all(rawBigDict, \"../RawFiles/RawbigDict.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the dictionary for stop:\n",
    "stopBigDict = {}\n",
    "print(stop_trained_frame[\"WordCount\"][stop_trained_frame[\"Type\"]==docType].tolist()[0])\n",
    "for docType in stop_trained_frame[\"Type\"]:\n",
    "    for key, value in stop_trained_frame[\"WordCount\"][stop_trained_frame[\"Type\"]==docType].tolist()[0].items():\n",
    "        #print(key + str(value))\n",
    "        stopBigDict[key+\"-\"+docType]=value[\"probability\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_it_all(stopBigDict, \"../StopFiles/stopBigDict.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
